{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YvYzoGSDPgLT",
    "outputId": "82e7c05d-1523-4a04-9fd8-634a17355c38",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip -qq install  peft\n",
    "# !pip -qq install  bitsandbytes\n",
    "# !pip -qq install  trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTgQUJ-iS5zz",
    "outputId": "4334f48e-ac97-437d-e591-260b728e00cb"
   },
   "outputs": [],
   "source": [
    "# !pip -qq install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "awiU5SDSQJtX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "from peft import LoraConfig, PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM , AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer , BitsAndBytesConfig\n",
    "\n",
    "from trl import SFTTrainer\n",
    "\n",
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "c92c28b4bd724043aa4780471d04b4e8",
      "068bc0b8d9074b1487576a9f6d0682b7",
      "b24659bf456549cd9adeb89a56624771",
      "e8f80ec8c697433aa7d2e7b6cd4e62fb",
      "e5dd3b54a1b2466fa62ebbbe1176153e",
      "2b8f2bdf3611471e8e69b76a91eccbc6",
      "efe9e27b86b540d6b77385bce2b62d4f",
      "dc6b0cbe3288481bac2e87112569aef0",
      "2b036691b30a44be9d727ff033dbd76c",
      "73dc9b7f901148949900ab6629f640f7",
      "1b134f1cff20483d927def2c0e94613c",
      "be60703fb74541fd9f91a68b38f8ce98",
      "e4f4f4e0f073479cb44a288b195db2bb",
      "55e2b7232d974a7d926c1bcfea982297",
      "b63a102c63864cd6a9a4f06b117c28e9",
      "eafb01ed20e5473bab38e66d7697294b",
      "7106e0589e394cacb1b0ac2051611c82",
      "ced0c2fd7ad14e16adb289d083a5ae9b",
      "27a0b1787c144f04b3965cfbb41630fb",
      "bb5ce5f2678b4b1e8605c29b78d8e3db",
      "70caeec39c844f41bb9c3649c05410ed",
      "017d11b29e1b49f6915668c844d90be6",
      "e5028d7f6bb74c7e932eaef1ddb9ee51",
      "3bc37d8e72b647c783852e0ade88d54b",
      "2d434c021c9d4395ad83a8ac8487bbf5",
      "5c090d00c2f94676b19f6f5a9e43a146",
      "2d824b707a5441b194a0ffa2406fe84e",
      "e0020b5d0413433eac71332c8cb1d8e3",
      "0311af00a4f3464caaddda4f3acdc075",
      "31ba866e30294a1d8586c887f4c6b1ad",
      "f62a453f03704800b99927ef4e455d8a",
      "89ab0574cd9a4bfeaf8acd35b82fcff7"
     ]
    },
    "id": "pw_1AkMlSCEb",
    "outputId": "623d3086-c3b8-4ca1-f573-9223f56d9660",
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset\n",
    "\n",
    "Salesforce/dialogstudio: \"TweetSumm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570,
     "referenced_widgets": [
      "e13406f92c824ee3b292de898148dc04",
      "7f5a7e719af84485984fc4808f8b6266",
      "2cff06b3f37e429d8d09c1e5083fb292",
      "8826761dbaf54bfa9e6a9d0f7fe7f999",
      "992ee5a93d4843c893d85435bc438bd0",
      "5a92ebe052934dac967a008c6fa1b302",
      "b9afeb9507744262bb59b3b6115e11d7",
      "31017356c0fd47ccb6243673fe1f050e",
      "a9e615fc3c3d47ef8ccedab33feec04e",
      "83382c2e725f420b8fd162b7b8dd21d2",
      "4715fb7fbffb461f936aa27ec00412dc",
      "9c832cf7055d434285ddf8dd90480e9b",
      "cefd5b024dcd429cb0e71005b2e3de37",
      "ba469a168231482cb09b5b8b53acf269",
      "707a7305ea90444ca4f5b2b6cc4ca6a3",
      "9bd7ad1dce1d4a88b7e4d5cae9b3b4e1",
      "8c15ee9843064c24853c890eb5703b51",
      "7a7f8b5cb6a14d3b98110640b48f91cb",
      "3355ec62d8a0490da97e02a4e94fc57a",
      "f4fa6c4eceb84b72b01949281cf36ffe",
      "f62d339badc74726b639c41293d6b318",
      "0747759e94ad43a8a15618c1815c696c"
     ]
    },
    "id": "jt8cehMsVMx7",
    "outputId": "0c61489d-d78a-4382-ceb0-4bdfa31c9b7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for Salesforce/dialogstudio contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Salesforce/dialogstudio\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['original dialog id', 'new dialog id', 'dialog index', 'original dialog info', 'log', 'prompt'],\n",
       "        num_rows: 879\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['original dialog id', 'new dialog id', 'dialog index', 'original dialog info', 'log', 'prompt'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['original dialog id', 'new dialog id', 'dialog index', 'original dialog info', 'log', 'prompt'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Salesforce/dialogstudio\", \"TweetSumm\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIrth1zwVhwp",
    "outputId": "25ca1a32-5d60-4be2-8b91-582176298688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original dialog id': 'b065262210783596c1fe79466b8f8985', 'new dialog id': 'TweetSumm--train--1', 'dialog index': 1, 'original dialog info': '{\"summaries\": {\"extractive_summaries\": [[{\"is_agent\": false, \"sentences\": [\"So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn\\\\u2019t recognise either source anymore for some reason.\"]}, {\"is_agent\": true, \"sentences\": [\"To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\"]}, {\"is_agent\": false, \"sentences\": [\"@AppleSupport My iPhone is on 11.1.2, and my watch is on 4.1.\"]}], [{\"is_agent\": false, \"sentences\": [\"So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn\\\\u2019t recognise either source anymore for some reason.\"]}, {\"is_agent\": true, \"sentences\": [\"To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\"]}], [{\"is_agent\": false, \"sentences\": [\"So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn\\\\u2019t recognise either source anymore for some reason.\"]}, {\"is_agent\": true, \"sentences\": [\"Have you tried restarting both devices since this started happening?\"]}, {\"is_agent\": false, \"sentences\": [\"@AppleSupport Yes, everything seems fine, it\\\\u2019s just Health and activity.\"]}, {\"is_agent\": true, \"sentences\": [\"@135060 Let\\\\u2019s move to DM and look into this a bit more.\"]}]], \"abstractive_summaries\": [[\"Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities.\", \"Agent is asking to move to DM and look into it.\"], [\"The customer has a problem.\", \"The agent in a very professional way tries to help the client.\"], [\"Health and activity functions are not working with the smartwatch and phone.\", \"Asks if the customer had restarted the items, offers to take this to DM to help resolve the issue.\"]]}}', 'log': [{'turn id': 1, 'user utterance': 'So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? https://t.co/m9DPQbkftD @AppleSupport please read the above.', 'system response': '@135060 Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?', 'dialog history': '', 'original user side information': '{}', 'original system side information': '{}'}, {'turn id': 2, 'user utterance': '@AppleSupport My iPhone is on 11.1.2, and my watch is on 4.1.', 'system response': '@135060 Thank you. Have you tried restarting both devices since this started happening?', 'dialog history': '<USER> So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? https://t.co/m9DPQbkftD @AppleSupport please read the above. <SYSTEM> @135060 Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?', 'original user side information': '{}', 'original system side information': '{}'}, {'turn id': 3, 'user utterance': '@AppleSupport I’ve restarted both, also un-paired then re-paired the watch.', 'system response': '@135060 Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?', 'dialog history': '<USER> So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? https://t.co/m9DPQbkftD @AppleSupport please read the above. <SYSTEM> @135060 Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently? <USER> @AppleSupport My iPhone is on 11.1.2, and my watch is on 4.1. <SYSTEM> @135060 Thank you. Have you tried restarting both devices since this started happening?', 'original user side information': '{}', 'original system side information': '{}'}, {'turn id': 4, 'user utterance': '@AppleSupport Yes, everything seems fine, it’s just Health and activity.', 'system response': '@135060 Let’s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app? https://t.co/GDrqU22YpT', 'dialog history': '<USER> So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? https://t.co/m9DPQbkftD @AppleSupport please read the above. <SYSTEM> @135060 Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently? <USER> @AppleSupport My iPhone is on 11.1.2, and my watch is on 4.1. <SYSTEM> @135060 Thank you. Have you tried restarting both devices since this started happening? <USER> @AppleSupport I’ve restarted both, also un-paired then re-paired the watch. <SYSTEM> @135060 Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?', 'original user side information': '{}', 'original system side information': '{}'}], 'prompt': ['']}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Default prompt that instructs the model to generate a summary.\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "Please provide a concise and accurate summary of the following conversation between a human and an AI agent.\n",
    "\"\"\".strip()\n",
    "\n",
    "class DatasetProcessor:\n",
    "    def __init__(self, data):\n",
    "        # Initialize the processor with the dataset.\n",
    "        self.data = data\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        \"\"\"\n",
    "        Clean the input text by removing URLs, user mentions, and extra whitespaces.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text to be cleaned.\n",
    "\n",
    "        Returns:\n",
    "            str: The cleaned text.\n",
    "        \"\"\"\n",
    "        text = re.sub(r\"http\\S+\", \"\", text)\n",
    "        text = re.sub(r\"@[^\\s]+\", \"\", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "        return re.sub(r\"\\^[^ ]+\", \"\", text)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_conversation_text(data_point):\n",
    "        \"\"\"\n",
    "        Construct the conversation text from a single data point's dialog log.\n",
    "        \n",
    "        Args:\n",
    "            data_point (dict): A single entry from the dataset.\n",
    "\n",
    "        Returns:\n",
    "            str: The formatted conversation text.\n",
    "        \"\"\"\n",
    "        text = \"\"\n",
    "        for item in data_point[\"log\"]:\n",
    "            user = DatasetProcessor.clean_text(item[\"user utterance\"])\n",
    "            text += f\"user: {user.strip()}\\n\"\n",
    "\n",
    "            agent = DatasetProcessor.clean_text(item[\"system response\"])\n",
    "            text += f\"agent: {agent.strip()}\\n\"\n",
    "\n",
    "        return text\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_training_prompt(conversation: str, summary: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT):\n",
    "        \"\"\"\n",
    "        Generate a formatted training prompt that includes the system prompt, the input conversation, and the expected response.\n",
    "        \n",
    "        Args:\n",
    "            conversation (str): The conversation text.\n",
    "            summary (str): The summary of the conversation.\n",
    "            system_prompt (str): Instructional text guiding the summary generation.\n",
    "\n",
    "        Returns:\n",
    "            str: The formatted training prompt.\n",
    "        \"\"\"\n",
    "        return f\"\"\"### Instruction: {system_prompt}\n",
    "\n",
    "        ### Input:\n",
    "        {conversation.strip()}\n",
    "\n",
    "        \"\"\".strip()\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_text(data_point):\n",
    "        \"\"\"\n",
    "        Generate the text components required for training, including the conversation text and its summary.\n",
    "        \n",
    "        Args:\n",
    "            data_point (dict): A single entry from the dataset.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the conversation, the summary, and the full training text.\n",
    "        \"\"\"\n",
    "        summaries = json.loads(data_point[\"original dialog info\"])[\"summaries\"][\"abstractive_summaries\"]\n",
    "        summary = \" \".join(summaries[0])\n",
    "\n",
    "        conversation_text = DatasetProcessor.create_conversation_text(data_point)\n",
    "        return {\n",
    "            \"conversation\": conversation_text,\n",
    "            \"summary\": summary,\n",
    "            \"new_prompt\": DatasetProcessor.generate_training_prompt(conversation_text, summary),\n",
    "        }\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Process the entire dataset by shuffling, generating text for each entry, and removing unnecessary columns.\n",
    "        \n",
    "        Returns:\n",
    "            Dataset: The processed dataset ready for use in training or evaluation.\n",
    "        \"\"\"\n",
    "        process_func = lambda x: DatasetProcessor.generate_text(x)\n",
    "        self.data = (\n",
    "            self.data.shuffle(seed=42)\n",
    "            .map(process_func)\n",
    "            .remove_columns(\n",
    "                [\n",
    "                    \"original dialog id\",\n",
    "                    \"new dialog id\",\n",
    "                    \"dialog index\",\n",
    "                    \"original dialog info\",\n",
    "                    \"log\",\n",
    "                    \"prompt\",\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        return self.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processing the dataset\n",
    "processor = DatasetProcessor(dataset[\"train\"])\n",
    "dataset[\"train\"] = processor.process()\n",
    "\n",
    "processor = DatasetProcessor(dataset[\"validation\"])\n",
    "dataset[\"validation\"] = processor.process()\n",
    "\n",
    "processor = DatasetProcessor(dataset[\"test\"])\n",
    "dataset[\"test\"] = processor.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversation', 'summary', 'new_prompt'],\n",
       "        num_rows: 879\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['conversation', 'summary', 'new_prompt'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['conversation', 'summary', 'new_prompt'],\n",
       "        num_rows: 110\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ybZMs_DeUsU",
    "outputId": "ed5fefbb-1fa4-4c42-bafe-b70d3d3370da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation': 'user: Do you have a plan to notify passengers well in advance of pilot related cancellations or just wait til the day before? Will you protect passengers on other airlines if flights are cancelled b/c of pilot shortages?\\nagent: We\\'re planning to fly as scheduled, Shaun.\\nuser: HOW ABOUT ANSWERING MY QUESTION. I\\'m asking if you do not get enough pilots to fly, which is a possibility, do you have a contingency plan in place on how to get customers to their destinations &amp; when will it be relayed to customers. THE DAY BEFORE WILL NOT BE ACCEPTABLE!\\nagent: Our team is working hard to avoid cancellations and you\\'ll be notified if otherwise.\\nuser: Your reading comprehension is terrible. WHEN WILL WE BE NOTIFIED? 3 hours b4 our flight so all other flights r sold out? Instead of Doug Parker making comments like \"I don\\'t think we\\'re ever going to lose money again,\" he should b assuring customers we\\'re getting home 4 XMAS\\nagent: As of now, flights are scheduled and we expect to avoid cancellations.\\nuser: This is like a Seinfeld skit. I know you have flights scheduled. But what about the pilots...are they scheduled? The answer to that ?? in many cases is probably NO. I know the AA twitter team is saying what the company tells u to say, but AA SUCKS at communication.\\nagent: We’re working to address this issue. We do expect to avoid cancellations this holiday season.\\n',\n",
       " 'summary': 'The customer is complaining that what will you do if there are no enough pilots to fly. The agent answered that as of now flights are scheduled and they have avoiding cancellations.',\n",
       " 'new_prompt': '### Instruction: Please provide a concise and accurate summary of the following conversation between a human and an AI agent.\\n\\n        ### Input:\\n        user: Do you have a plan to notify passengers well in advance of pilot related cancellations or just wait til the day before? Will you protect passengers on other airlines if flights are cancelled b/c of pilot shortages?\\nagent: We\\'re planning to fly as scheduled, Shaun.\\nuser: HOW ABOUT ANSWERING MY QUESTION. I\\'m asking if you do not get enough pilots to fly, which is a possibility, do you have a contingency plan in place on how to get customers to their destinations &amp; when will it be relayed to customers. THE DAY BEFORE WILL NOT BE ACCEPTABLE!\\nagent: Our team is working hard to avoid cancellations and you\\'ll be notified if otherwise.\\nuser: Your reading comprehension is terrible. WHEN WILL WE BE NOTIFIED? 3 hours b4 our flight so all other flights r sold out? Instead of Doug Parker making comments like \"I don\\'t think we\\'re ever going to lose money again,\" he should b assuring customers we\\'re getting home 4 XMAS\\nagent: As of now, flights are scheduled and we expect to avoid cancellations.\\nuser: This is like a Seinfeld skit. I know you have flights scheduled. But what about the pilots...are they scheduled? The answer to that ?? in many cases is probably NO. I know the AA twitter team is saying what the company tells u to say, but AA SUCKS at communication.\\nagent: We’re working to address this issue. We do expect to avoid cancellations this holiday season.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "73f0d6d8ab0042bc90436030127c3180",
      "ffd34f646342432a956810303aef59cf",
      "da53bda3f01d46898b3a2105d7356c80",
      "f6f0ca60a6ce4aa29f3c241b17e8fb46",
      "88af9bfbc9f249088c3bbdc55be523a1",
      "03e9c632eb31417282be6050a10a7ffe",
      "b91b5f88a5d24fcb9228868de7773604",
      "f38eaf716a424225979b7eec4b7e2a05",
      "48d064da1da04cffbd32b8440bdfdf04",
      "1dcd269a5e0c4122a4fca7be44b0a35d",
      "9ae6eed0fb184269bc1c283078a4ec93",
      "d5c88931586841ea9204e8d3c2193de1",
      "b78321f7550043fa9e520201b7cd483a",
      "4408ec6e1f854c7688db481ead19d637",
      "56a1b51b999e45c1942a200de8afaea8",
      "cb4e1af2b227433589feab9798332525",
      "d5de76fcdd08405da1918e0874eabfbd",
      "645c2980da484817ade24c762ddff101",
      "69593d00ba1548369e6cce2d9c6500d8",
      "07206333d31a44959be04a5f8c586536",
      "b61131c94e8f471db054027fe6fce205",
      "01086900e35842a3982a72dd4dfd7ed4"
     ]
    },
    "id": "t4s8r1IxWksb",
    "outputId": "ded8244c-afff-49c3-f329-a2ec174a6870",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:703: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-3b-4e1t\", use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"stabilityai/stablelm-3b-4e1t\", torch_dtype=torch.bfloat16,use_auth_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZcWTEgWpqzvB"
   },
   "outputs": [],
   "source": [
    "# Create dataframes from the dataset\n",
    "train_df = pd.DataFrame(dataset[\"train\"])\n",
    "validation_df = pd.DataFrame(dataset[\"validation\"])\n",
    "test_df = pd.DataFrame(dataset[\"test\"])\n",
    "\n",
    "# Save dataframes to CSV files\n",
    "train_df.to_csv(\"train.csv\", index=False, columns=[\"conversation\", \"new_prompt\", \"summary\"])\n",
    "validation_df.to_csv(\"validation.csv\", index=False, columns=[\"conversation\", \"new_prompt\", \"summary\"])\n",
    "test_df.to_csv(\"test.csv\", index=False, columns=[\"conversation\", \"new_prompt\", \"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "s8RJtoLnXbgp",
    "outputId": "b8240e9e-5632-4bea-e38c-027cc5f12b4a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i19AgrV8rDwi"
   },
   "source": [
    "# In Context Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation': \"user: On went to buy a Lip na mpesa wrist band in your shop in Thika and was sent to Annas Mall where i dint find your Team!\\nagent: Apologies for this, check with any M-PESA Agent, or Safaricom authorized dealer. You may also go back to our shop in Thika -(contd)to verify whether we have restocked.\\nuser: I was at your shop at Thika and they told me they were not sure where the guys dealing with the wrist bands were\\nagent: The mpesa 1 tap is not available at Thika its being piloted in Nairobi, Mombasa, Kisumu, Eldoret and Nyeri towns ... cont... currently. To get it you may visit the nearest town which is Nairobi to purchase one at a cost of 20/-.\\nuser: Would you please confirm for me if I will get the wrist band at your shop in Moi Avenue today so I don't have to travel for nothing.\\nagent: Hi, yes you will and at the moment it can only be used in the towns mentioned in our previous response only.\\nuser: On Tuesday I went to your shop on Moi Avenue to get wrist band but was told they ended,but was told I would be informed when they are ready Cont...Are they still not ready yet? ?\\nagent: Hi, you can visit any authorized dealer or the other shops in town for one.\\n\",\n",
       " 'summary': 'Customer wants the wrist band which was not available in the stop so customer says to confirm if the wrist band is present. Agent says to visit any authorized dealer or shop in town for one.',\n",
       " 'new_prompt': \"### Instruction: Please provide a concise and accurate summary of the following conversation between a human and an AI agent.\\n\\n        ### Input:\\n        user: On went to buy a Lip na mpesa wrist band in your shop in Thika and was sent to Annas Mall where i dint find your Team!\\nagent: Apologies for this, check with any M-PESA Agent, or Safaricom authorized dealer. You may also go back to our shop in Thika -(contd)to verify whether we have restocked.\\nuser: I was at your shop at Thika and they told me they were not sure where the guys dealing with the wrist bands were\\nagent: The mpesa 1 tap is not available at Thika its being piloted in Nairobi, Mombasa, Kisumu, Eldoret and Nyeri towns ... cont... currently. To get it you may visit the nearest town which is Nairobi to purchase one at a cost of 20/-.\\nuser: Would you please confirm for me if I will get the wrist band at your shop in Moi Avenue today so I don't have to travel for nothing.\\nagent: Hi, yes you will and at the moment it can only be used in the towns mentioned in our previous response only.\\nuser: On Tuesday I went to your shop on Moi Avenue to get wrist band but was told they ended,but was told I would be informed when they are ready Cont...Are they still not ready yet? ?\\nagent: Hi, you can visit any authorized dealer or the other shops in town for one.\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Customer is asking help that  how to remove red eye in ligth room cc even he cant find it in tool  and even customer want some new advance features. Agent is giving details on it and then sends a link where he can get help and also asked customer to  report a  complaint where  his engineer team will  get alert and help him over it.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "ORIGINAL MODEL:\n",
      "\n",
      "Please provide a concise and accurate summary of the following conversation between a human and an AI agent.\n",
      "user: Can you tell me how to do Red Eye Removal in Lightroom CC? I just moved to it and don't see the Red Eye Removal tool.\n",
      "agent: Hi Bob, here is a link to show you to use the Red eye removal in Lightroom CC.\n",
      "user: Does not apply to the NEW LightRoom CC. Any other suggestions?\n",
      "agent: Bob, I will loop in our Lightroom expert to help you with this. The setting may have moved to a different location.  Hi Bob, I am looping our expert team to help answer your question. They will get back to you ASAP. Please excuse the delay, if any. Thanks!  Hi Bob, Yes, its not there in Lightroom CC also, refer: Thanks.\n",
      "user: Thank you. I wish a list of feathers missing in Lightroom CC would have been noted before I migrated my library. Never thought a commercial photo app from Adobe would omit a basic feature like that. *features\n",
      "agent: Hi Bob, you can report this here to alert our product teams and engineers: Thanks!  Hi Bob, this feature is not available in Lightroom CC as of now, however you may suggest it as a feature here:.\n",
      "user: Hate to be “that guy” but this is a Photo Editing 101 feature. Where is the list of what’s missing from the “new” Lightroom CC? Also, it would be great if included “Lightroom CC” in its support system. Only “PhotoShop Lightroom” is listed on that page. So if I request it, I'd probably get back an \"Already available\" response.\n",
      "agent: We have released Lightroom Classic CC which has all the features the old Lightroom CC 2015.12 had, you can check this article to see the differences betweem LR Classic &amp; the new Lightroom CC:.\n",
      "\n",
      "\n",
      "Summary: \n",
      "The conversation was about a missing feature in Lightroom CC. The agent was unable to provide a solution. The agent suggested the user report the missing feature to Adobe. The user was not satisfied with the response.\n",
      "\n",
      "A: I'm not sure if this is the best way to do it, but I've had some success with this.\n",
      "I've had a few conversations with Adobe support where I've been told that the feature I'm asking about is not available in the product I'm using. I've then asked for a list of features that are not available in the product I'm using.\n",
      "I've found that this has worked well for me. I've been able to get a list of features that are not available in the product I'm using.\n",
      "\n",
      "A: I have had a similar experience with Adobe support. I have found that the best way to get a list of features that are not available in the product I am using is to ask for a list of features that are available in the product I am using.\n",
      "I have found that this has worked well for me. I have been able to get a list of features that are available in the product I am using.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 100\n",
    "dialogue = dataset['test'][index]['conversation']\n",
    "baseline_human_summary = dataset['test'][index]['summary']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please provide a concise and accurate summary of the following conversation between a human and an AI agent.\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs = {key: value.to(\"cuda:1\") for key, value in input_ids.items()} \n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    max_length=2048, \n",
    "    num_beams=1,\n",
    "    pad_token_id=tokenizer.eos_token_id  ,\n",
    "    temperature=0.7,\n",
    "\n",
    ")\n",
    "\n",
    "original_model_outputs = model.generate(input_ids=inputs[\"input_ids\"], generation_config=generation_config)\n",
    "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{baseline_human_summary}')\n",
    "print(dash_line)\n",
    "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Customer is asking help that  how to remove red eye in ligth room cc even he cant find it in tool  and even customer want some new advance features. Agent is giving details on it and then sends a link where he can get help and also asked customer to  report a  complaint where  his engineer team will  get alert and help him over it.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONE-SHOT MODEL OUTPUT:\n",
      "\n",
      "### Example Conversation:\n",
      "user: Do you have a plan to notify passengers well in advance of pilot related cancellations or just wait til the day before? Will you protect passengers on other airlines if flights are cancelled b/c of pilot shortages?\n",
      "agent: We're planning to fly as scheduled, Shaun.\n",
      "user: HOW ABOUT ANSWERING MY QUESTION. I'm asking if you do not get enough pilots to fly, which is a possibility, do you have a contingency plan in place on how to get customers to their destinations &amp; when will it be relayed to customers. THE DAY BEFORE WILL NOT BE ACCEPTABLE!\n",
      "agent: Our team is working hard to avoid cancellations and you'll be notified if otherwise.\n",
      "user: Your reading comprehension is terrible. WHEN WILL WE BE NOTIFIED? 3 hours b4 our flight so all other flights r sold out? Instead of Doug Parker making comments like \"I don't think we're ever going to lose money again,\" he should b assuring customers we're getting home 4 XMAS\n",
      "agent: As of now, flights are scheduled and we expect to avoid cancellations.\n",
      "user: This is like a Seinfeld skit. I know you have flights scheduled. But what about the pilots...are they scheduled? The answer to that?? in many cases is probably NO. I know the AA twitter team is saying what the company tells u to say, but AA SUCKS at communication.\n",
      "agent: We’re working to address this issue. We do expect to avoid cancellations this holiday season.\n",
      "\n",
      "\n",
      "### Example Summary:\n",
      "The customer is complaining that what will you do if there are no enough pilots to fly. The agent answered that as of now flights are scheduled and they have avoiding cancellations.\n",
      "\n",
      "---\n",
      "\n",
      "### New Conversation:\n",
      "user: Can you tell me how to do Red Eye Removal in Lightroom CC? I just moved to it and don't see the Red Eye Removal tool.\n",
      "agent: Hi Bob, here is a link to show you to use the Red eye removal in Lightroom CC.\n",
      "user: Does not apply to the NEW LightRoom CC. Any other suggestions?\n",
      "agent: Bob, I will loop in our Lightroom expert to help you with this. The setting may have moved to a different location.  Hi Bob, I am looping our expert team to help answer your question. They will get back to you ASAP. Please excuse the delay, if any. Thanks!  Hi Bob, Yes, its not there in Lightroom CC also, refer: Thanks.\n",
      "user: Thank you. I wish a list of feathers missing in Lightroom CC would have been noted before I migrated my library. Never thought a commercial photo app from Adobe would omit a basic feature like that. *features\n",
      "agent: Hi Bob, you can report this here to alert our product teams and engineers: Thanks!  Hi Bob, this feature is not available in Lightroom CC as of now, however you may suggest it as a feature here:.\n",
      "user: Hate to be “that guy” but this is a Photo Editing 101 feature. Where is the list of what’s missing from the “new” Lightroom CC? Also, it would be great if included “Lightroom CC” in its support system. Only “PhotoShop Lightroom” is listed on that page. So if I request it, I'd probably get back an \"Already available\" response.\n",
      "agent: We have released Lightroom Classic CC which has all the features the old Lightroom CC 2015.12 had, you can check this article to see the differences betweem LR Classic &amp; the new Lightroom CC:.\n",
      "\n",
      "\n",
      "### Please provide a concise and accurate summary for the new conversation above:\n",
      "\n",
      "The customer is complaining that he is not able to find the Red Eye Removal tool in Lightroom CC. The agent answered that the feature is not available in Lightroom CC as of now.\n",
      "\n",
      "---\n",
      "\n",
      "### Example Conversation:\n",
      "user: I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select a random conversation-summary pair from the train dataset for the one-shot example\n",
    "example_conversation_train = dataset['train'][0]['conversation']\n",
    "example_summary_train =  dataset['train'][0]['summary']\n",
    "\n",
    "# Select the conversation and the human-generated summary from the test dataset\n",
    "index = 100  \n",
    "dialogue_test = dataset['test'][index]['conversation']\n",
    "baseline_human_summary = dataset['test'][index]['summary']\n",
    "\n",
    "\n",
    "# Prepare the one-shot prompt\n",
    "prompt = f\"\"\"\n",
    "### Example Conversation:\n",
    "{example_conversation_train}\n",
    "\n",
    "### Example Summary:\n",
    "{example_summary_train}\n",
    "\n",
    "---\n",
    "\n",
    "### New Conversation:\n",
    "{dialogue_test}\n",
    "\n",
    "### Please provide a concise and accurate summary for the new conversation above:\n",
    "\"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs = {key: value.to(\"cuda:1\") for key, value in input_ids.items()} \n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    max_length=1024, \n",
    "    num_beams=1,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Generate the summary for the new conversation\n",
    "original_model_outputs = model.generate(input_ids=inputs[\"input_ids\"], generation_config=generation_config)\n",
    "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Output the results\n",
    "dash_line = '-' * 100\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{baseline_human_summary}')\n",
    "print(dash_line)\n",
    "print(f'ONE-SHOT MODEL OUTPUT:\\n{original_model_text_output}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:703: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## load again model and tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-3b-4e1t\", use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"stabilityai/stablelm-3b-4e1t\", torch_dtype=torch.bfloat16,use_auth_token=True, trust_remote_code=True)\n",
    "\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#         load_in_4bit=True,\n",
    "#         bnb_4bit_quant_type=\"nf4\",\n",
    "#         bnb_4bit_compute_dtype=torch.float16,\n",
    "#     )\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"stabilityai/stablelm-3b-4e1t\",\n",
    "#     use_safetensors=True,\n",
    "#     quantization_config=bnb_config,\n",
    "#     trust_remote_code=True,\n",
    "#     use_auth_token=True,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "z2OSx3CfsO-x",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load dataset from csvs\n",
    "\n",
    "dataset = load_dataset('csv', data_files={\n",
    "    'train': 'train.csv',\n",
    "    'validation': 'validation.csv',\n",
    "    'test': 'test.csv'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-2NMP_KsTZU",
    "outputId": "fb5338ff-da48-4116-9bc9-86840db73de1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add [PAD] as the padding token\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sAPu27PLrdUz",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1298c6cc04824f46bc4f48a56560533b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def tokenize_prompts_and_summaries(examples):\n",
    "    \"\"\"\n",
    "    Tokenizes the prompts and summaries from the given examples.\n",
    "\n",
    "    This function takes a dictionary `examples` with keys 'new_prompt' and 'summary'. It tokenizes both the prompts and summaries,\n",
    "    pads them to a maximum length, and truncates if necessary. The tokenized inputs are then added to the `examples` dictionary\n",
    "    under the keys 'input_ids' for the prompts and 'labels' for the summaries.\n",
    "\n",
    "    Parameters:\n",
    "    examples (dict): A dictionary containing 'new_prompt' and 'summary' keys. 'new_prompt' is a list of prompts, and 'summary' is a list of corresponding summaries.\n",
    "\n",
    "    Returns:\n",
    "    dict: The original `examples` dictionary updated with 'input_ids' for tokenized prompts and 'labels' for tokenized summaries.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the end of the prompt token\n",
    "    end_prompt_token = '\\n\\nSummary: '\n",
    "\n",
    "    # Concatenate end of prompt token with each new prompt\n",
    "    prompts = [new_prompt + end_prompt_token for new_prompt in examples[\"new_prompt\"]]\n",
    "\n",
    "    # Tokenizing the prompts and the summaries\n",
    "    tokenized_inputs = tokenizer(prompts, padding=\"max_length\", truncation=True, max_length=1024, return_tensors=\"pt\")\n",
    "    tokenized_labels = tokenizer(examples[\"summary\"], padding=\"max_length\", truncation=True, max_length=1024, return_tensors=\"pt\")\n",
    "\n",
    "    # Extracting input_ids for inputs and labels\n",
    "    examples['input_ids'] = tokenized_inputs.input_ids\n",
    "    examples['labels'] = tokenized_labels.input_ids\n",
    "\n",
    "    return examples\n",
    "\n",
    "\n",
    "# Apply the function to the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_prompts_and_summaries, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NN3FzC_fscai",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove columns\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['conversation', 'summary' , 'new_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8j_G2g8_rFFO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################### if dont want to load from csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "C7GtgIlfYcAG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def tokenize_function(example):\n",
    "#     example['input_ids'] = tokenizer(example[\"new_prompt\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "#     example['labels'] = tokenizer(example[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "\n",
    "#     return example\n",
    "\n",
    "# tokenized_datasets = dataset.map(tokenize_function)\n",
    "# tokenized_datasets = tokenized_datasets.remove_columns(['conversation', 'new_prompt', 'summary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CPwH_2qUa1AC",
    "outputId": "b20340d2-be82-45a1-8243-c74d5e2f9471",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: (879, 2)\n",
      "Validation: (110, 2)\n",
      "Test: (110, 2)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 879\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 110\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 110\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
    "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
    "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
    "\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ueQBY443fTdU",
    "outputId": "debd0184-3c81-4eca-af5e-53ab2acd589e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_model_parameters(model):\n",
    "    \"\"\"\n",
    "    Counts the total and trainable parameters of the given model.\n",
    "\n",
    "    This function iterates through all parameters of the provided model, counting the total number of parameters\n",
    "    and the number of trainable parameters (parameters with requires_grad=True).\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model whose parameters are to be counted.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the number of trainable parameters and the total number of parameters.\n",
    "    \"\"\"\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    return trainable_params, total_params\n",
    "\n",
    "def print_model_parameters_info(model):\n",
    "    \"\"\"\n",
    "    Prints the number of total and trainable parameters of the given model, along with the percentage of trainable parameters.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model whose parameter information is to be printed.\n",
    "    \"\"\"\n",
    "    trainable_params, total_params = count_model_parameters(model)\n",
    "    percentage_trainable = 100 * trainable_params / total_params\n",
    "    info_message = (\n",
    "        f\"Trainable model parameters: {trainable_params}\\n\"\n",
    "        f\"All model parameters: {total_params}\\n\"\n",
    "        f\"Percentage of trainable model parameters: {percentage_trainable:.2f}%\"\n",
    "    )\n",
    "    print(info_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable model parameters: 2795443200\n",
      "All model parameters: 2795443200\n",
      "Percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# print model info \n",
    "print_model_parameters_info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0etaZKWfewjG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_r = 16\n",
    "lora_alpha = 64\n",
    "lora_dropout = 0.1\n",
    "lora_target_modules = [\n",
    "    \"q_proj\",\n",
    "    \"k_proj\",\n",
    "    \"v_proj\"\n",
    "]\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=lora_target_modules,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5gfAshHe3iL",
    "outputId": "74da5e51-a32e-45bb-e732-9abbf778d9d5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable model parameters: 7864320\n",
      "All model parameters: 2803307520\n",
      "Percentage of trainable model parameters: 0.28%\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(model,\n",
    "                            peft_config)\n",
    "\n",
    "# Print peft info\n",
    "print_model_parameters_info(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TXh68y3qfCeq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "peft_training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=500,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQg3QYLmfizS",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='551' max='1760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 551/1760 19:52 < 43:46, 0.46 it/s, Epoch 1.25/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>8.169900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfw9BEPafmt5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "peft_model_path=\"./peft-model-checkpoint-new\"\n",
    "\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Fine-Tuned Peft Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:703: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load model again\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-3b-4e1t\", use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"stabilityai/stablelm-3b-4e1t\", torch_dtype=torch.bfloat16,use_auth_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# Base Model to Cuda\n",
    "model.to(\"cuda:1\")\n",
    "model.eval()\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_r = 16\n",
    "lora_alpha = 64\n",
    "lora_dropout = 0.1\n",
    "lora_target_modules = [\n",
    "    \"q_proj\",\n",
    "    \"v_proj\"\n",
    "]\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=lora_target_modules,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model,\n",
    "                            peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load PEFT Fine Tuned Model\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model, \n",
    "                                       './peft-model-checkpoint-new/', \n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peft_model loaded\n"
     ]
    }
   ],
   "source": [
    "peft_model.to(\"cuda:1\")\n",
    "peft_model.eval()\n",
    "print(\"peft_model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Customer is asking help that  how to remove red eye in ligth room cc even he cant find it in tool  and even customer want some new advance features. Agent is giving details on it and then sends a link where he can get help and also asked customer to  report a  complaint where  his engineer team will  get alert and help him over it.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "PEFT MODEL: \n",
      "Summarize the following conversation.\n",
      "\n",
      "user: Can you tell me how to do Red Eye Removal in Lightroom CC? I just moved to it and don't see the Red Eye Removal tool.\n",
      "agent: Hi Bob, here is a link to show you to use the Red eye removal in Lightroom CC.\n",
      "user: Does not apply to the NEW LightRoom CC. Any other suggestions?\n",
      "agent: Bob, I will loop in our Lightroom expert to help you with this. The setting may have moved to a different location.  Hi Bob, I am looping our expert team to help answer your question. They will get back to you ASAP. Please excuse the delay, if any. Thanks!  Hi Bob, Yes, its not there in Lightroom CC also, refer: Thanks.\n",
      "user: Thank you. I wish a list of feathers missing in Lightroom CC would have been noted before I migrated my library. Never thought a commercial photo app from Adobe would omit a basic feature like that. *features\n",
      "agent: Hi Bob, you can report this here to alert our product teams and engineers: Thanks!  Hi Bob, this feature is not available in Lightroom CC as of now, however you may suggest it as a feature here:.\n",
      "user: Hate to be “that guy” but this is a Photo Editing 101 feature. Where is the list of what’s missing from the “new” Lightroom CC? Also, it would be great if included “Lightroom CC” in its support system. Only “PhotoShop Lightroom” is listed on that page. So if I request it, I'd probably get back an \"Already available\" response.\n",
      "agent: We have released Lightroom Classic CC which has all the features the old Lightroom CC 2015.12 had, you can check this article to see the differences betweem LR Classic &amp; the new Lightroom CC:.\n",
      "\n",
      "\n",
      "Summary: \n",
      "The conversation is about a missing feature in Lightroom CC. The user is frustrated that the feature is missing. The agent is trying to help the user by providing a link to a page that shows how to use the feature. The user is not satisfied with the response and asks for a list of missing features. The agent is not sure what the user is asking for and asks for help from a Lightroom expert. The user is not satisfied with the response and asks for a list of missing features. The agent is not sure what\n"
     ]
    }
   ],
   "source": [
    "index = 100\n",
    "dialogue = dataset['test'][index]['conversation']\n",
    "baseline_human_summary = dataset['test'][index]['summary']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs = {key: value.to(\"cuda:1\") for key, value in input_ids.items()} \n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    max_length=512, \n",
    "    num_beams=1,\n",
    "    pad_token_id=tokenizer.eos_token_id  ,\n",
    "    temperature=0,\n",
    "\n",
    ")\n",
    "\n",
    "peft_model_outputs = peft_model.generate(input_ids=inputs[\"input_ids\"], generation_config=generation_config)\n",
    "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{baseline_human_summary}')\n",
    "print(dash_line)\n",
    "print(f'PEFT MODEL: {peft_model_text_output}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_baseline_summaries</th>\n",
       "      <th>peft_model_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Customer is looking to change the flight on Fr...</td>\n",
       "      <td>\\nThe agent is asking the user to call to make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer is unable to use an app. Agent inform...</td>\n",
       "      <td>\\nThe user is having trouble logging in to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Customer is complaining that he is unable to p...</td>\n",
       "      <td>\\nThe user was having an issue with being kick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Customer is saying that headphones are not wor...</td>\n",
       "      <td>\\nThe conversation was about a user's problem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer booked the flight but with wrong birt...</td>\n",
       "      <td>\\nI have a conversation with the agent and I h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Customer is complaining that the watchlist is ...</td>\n",
       "      <td>\\nThe conversation is about a user's watchlist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Customer is complaining about customer service...</td>\n",
       "      <td>\\nThe user is complaining about Sprint's custo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Customer is enquiring about streaming music wi...</td>\n",
       "      <td>\\nThe agent was able to summarize the conversa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Customer is reporting to watch live programs w...</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The customer is complaining that he facing som...</td>\n",
       "      <td>\\nThe conversation is about a store that has h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            human_baseline_summaries  \\\n",
       "0  Customer is looking to change the flight on Fr...   \n",
       "1  Customer is unable to use an app. Agent inform...   \n",
       "2  Customer is complaining that he is unable to p...   \n",
       "3  Customer is saying that headphones are not wor...   \n",
       "4  Customer booked the flight but with wrong birt...   \n",
       "5  Customer is complaining that the watchlist is ...   \n",
       "6  Customer is complaining about customer service...   \n",
       "7  Customer is enquiring about streaming music wi...   \n",
       "8  Customer is reporting to watch live programs w...   \n",
       "9  The customer is complaining that he facing som...   \n",
       "\n",
       "                                peft_model_summaries  \n",
       "0  \\nThe agent is asking the user to call to make...  \n",
       "1  \\nThe user is having trouble logging in to the...  \n",
       "2  \\nThe user was having an issue with being kick...  \n",
       "3  \\nThe conversation was about a user's problem ...  \n",
       "4  \\nI have a conversation with the agent and I h...  \n",
       "5  \\nThe conversation is about a user's watchlist...  \n",
       "6  \\nThe user is complaining about Sprint's custo...  \n",
       "7  \\nThe agent was able to summarize the conversa...  \n",
       "8                                                 \\n  \n",
       "9  \\nThe conversation is about a store that has h...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogues = dataset['test'][0:10]['conversation']\n",
    "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
    "\n",
    "peft_model_summaries = []\n",
    "generation_config = GenerationConfig(\n",
    "    max_length=512, \n",
    "    num_beams=1,\n",
    "    pad_token_id=tokenizer.eos_token_id  ,\n",
    "    temperature=0,\n",
    "\n",
    ")\n",
    "for idx, dialogue in enumerate(dialogues):\n",
    "    prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    inputs = {key: value.to(\"cuda:1\") for key, value in input_ids.items()} \n",
    "\n",
    "\n",
    "    human_baseline_text_output = human_baseline_summaries[idx]\n",
    "    \n",
    "\n",
    "    peft_model_outputs = peft_model.generate(input_ids=inputs[\"input_ids\"], generation_config=generation_config)\n",
    "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "    last_summary_part = peft_model_text_output.split('Summary: ')[-1]  # Get the last part of the summary\n",
    "\n",
    "    peft_model_summaries.append(last_summary_part)\n",
    "\n",
    "zipped_summaries = list(zip(human_baseline_summaries, peft_model_summaries))\n",
    " \n",
    "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries','peft_model_summaries'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT MODEL:\n",
      "{'rouge1': 0.12776677911580778, 'rouge2': 0.03871861188881383, 'rougeL': 0.10721665788214924, 'rougeLsum': 0.10683639087848884}\n"
     ]
    }
   ],
   "source": [
    "peft_model_results = rouge.compute(\n",
    "    predictions=peft_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('PEFT MODEL:')\n",
    "print(peft_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEFT Model Zero-Shot Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/whisper_asr/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Customer is asking help that  how to remove red eye in ligth room cc even he cant find it in tool  and even customer want some new advance features. Agent is giving details on it and then sends a link where he can get help and also asked customer to  report a  complaint where  his engineer team will  get alert and help him over it.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Peft Model Zero shot MODEL:\n",
      "\n",
      "Please provide a concise and accurate summary of the following conversation between a human and an AI agent.\n",
      "user: Can you tell me how to do Red Eye Removal in Lightroom CC? I just moved to it and don't see the Red Eye Removal tool.\n",
      "agent: Hi Bob, here is a link to show you to use the Red eye removal in Lightroom CC.\n",
      "user: Does not apply to the NEW LightRoom CC. Any other suggestions?\n",
      "agent: Bob, I will loop in our Lightroom expert to help you with this. The setting may have moved to a different location.  Hi Bob, I am looping our expert team to help answer your question. They will get back to you ASAP. Please excuse the delay, if any. Thanks!  Hi Bob, Yes, its not there in Lightroom CC also, refer: Thanks.\n",
      "user: Thank you. I wish a list of feathers missing in Lightroom CC would have been noted before I migrated my library. Never thought a commercial photo app from Adobe would omit a basic feature like that. *features\n",
      "agent: Hi Bob, you can report this here to alert our product teams and engineers: Thanks!  Hi Bob, this feature is not available in Lightroom CC as of now, however you may suggest it as a feature here:.\n",
      "user: Hate to be “that guy” but this is a Photo Editing 101 feature. Where is the list of what’s missing from the “new” Lightroom CC? Also, it would be great if included “Lightroom CC” in its support system. Only “PhotoShop Lightroom” is listed on that page. So if I request it, I'd probably get back an \"Already available\" response.\n",
      "agent: We have released Lightroom Classic CC which has all the features the old Lightroom CC 2015.12 had, you can check this article to see the differences betweem LR Classic &amp; the new Lightroom CC:.\n",
      "\n",
      "\n",
      "Summary: \n",
      "The conversation was about a missing feature in Lightroom CC. The agent was unable to provide a solution. The agent suggested the user report the missing feature to Adobe. The user was not satisfied with the response.\n",
      "\n",
      "A: I'm not sure if this is the best way to do it, but I've had some success with this.\n",
      "I've had a few conversations with Adobe support where I've been told that the feature I'm asking about is not available in the product I'm using. I've then asked for a list of features that are not available in the product I'm using.\n",
      "I've found that this has worked well for me. I've been able to get a list of features that are not available in the product I'm using.\n",
      "\n",
      "A: I have had a similar experience with Adobe support. I have found that the best way to get a list of features that are not available in the product I am using is to ask for a list of features that are available in the product I am using.\n",
      "I have found that this has worked well for me. I have been able to get a list of features that are available in the product I am using.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 100\n",
    "dialogue = dataset['test'][index]['conversation']\n",
    "baseline_human_summary = dataset['test'][index]['summary']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please provide a concise and accurate summary of the following conversation between a human and an AI agent.\n",
    "{dialogue}\n",
    "\n",
    "Summary: \"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs = {key: value.to(\"cuda:1\") for key, value in input_ids.items()} \n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    max_length=2048, \n",
    "    num_beams=1,\n",
    "    pad_token_id=tokenizer.eos_token_id  ,\n",
    "    temperature=0.7,\n",
    "\n",
    ")\n",
    "\n",
    "peft_model_outputs = peft_model.generate(input_ids=inputs[\"input_ids\"], generation_config=generation_config)\n",
    "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{baseline_human_summary}')\n",
    "print(dash_line)\n",
    "print(f'Peft Model Zero shot MODEL:\\n{peft_model_text_output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEFT Model One-Shot Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Customer is asking help that  how to remove red eye in ligth room cc even he cant find it in tool  and even customer want some new advance features. Agent is giving details on it and then sends a link where he can get help and also asked customer to  report a  complaint where  his engineer team will  get alert and help him over it.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ONE-SHOT MODEL OUTPUT:\n",
      "\n",
      "### Example Conversation:\n",
      "user: Do you have a plan to notify passengers well in advance of pilot related cancellations or just wait til the day before? Will you protect passengers on other airlines if flights are cancelled b/c of pilot shortages?\n",
      "agent: We're planning to fly as scheduled, Shaun.\n",
      "user: HOW ABOUT ANSWERING MY QUESTION. I'm asking if you do not get enough pilots to fly, which is a possibility, do you have a contingency plan in place on how to get customers to their destinations &amp; when will it be relayed to customers. THE DAY BEFORE WILL NOT BE ACCEPTABLE!\n",
      "agent: Our team is working hard to avoid cancellations and you'll be notified if otherwise.\n",
      "user: Your reading comprehension is terrible. WHEN WILL WE BE NOTIFIED? 3 hours b4 our flight so all other flights r sold out? Instead of Doug Parker making comments like \"I don't think we're ever going to lose money again,\" he should b assuring customers we're getting home 4 XMAS\n",
      "agent: As of now, flights are scheduled and we expect to avoid cancellations.\n",
      "user: This is like a Seinfeld skit. I know you have flights scheduled. But what about the pilots...are they scheduled? The answer to that?? in many cases is probably NO. I know the AA twitter team is saying what the company tells u to say, but AA SUCKS at communication.\n",
      "agent: We’re working to address this issue. We do expect to avoid cancellations this holiday season.\n",
      "\n",
      "\n",
      "### Example Summary:\n",
      "The customer is complaining that what will you do if there are no enough pilots to fly. The agent answered that as of now flights are scheduled and they have avoiding cancellations.\n",
      "\n",
      "---\n",
      "\n",
      "### New Conversation:\n",
      "user: Can you tell me how to do Red Eye Removal in Lightroom CC? I just moved to it and don't see the Red Eye Removal tool.\n",
      "agent: Hi Bob, here is a link to show you to use the Red eye removal in Lightroom CC.\n",
      "user: Does not apply to the NEW LightRoom CC. Any other suggestions?\n",
      "agent: Bob, I will loop in our Lightroom expert to help you with this. The setting may have moved to a different location.  Hi Bob, I am looping our expert team to help answer your question. They will get back to you ASAP. Please excuse the delay, if any. Thanks!  Hi Bob, Yes, its not there in Lightroom CC also, refer: Thanks.\n",
      "user: Thank you. I wish a list of feathers missing in Lightroom CC would have been noted before I migrated my library. Never thought a commercial photo app from Adobe would omit a basic feature like that. *features\n",
      "agent: Hi Bob, you can report this here to alert our product teams and engineers: Thanks!  Hi Bob, this feature is not available in Lightroom CC as of now, however you may suggest it as a feature here:.\n",
      "user: Hate to be “that guy” but this is a Photo Editing 101 feature. Where is the list of what’s missing from the “new” Lightroom CC? Also, it would be great if included “Lightroom CC” in its support system. Only “PhotoShop Lightroom” is listed on that page. So if I request it, I'd probably get back an \"Already available\" response.\n",
      "agent: We have released Lightroom Classic CC which has all the features the old Lightroom CC 2015.12 had, you can check this article to see the differences betweem LR Classic &amp; the new Lightroom CC:.\n",
      "\n",
      "\n",
      "### Please provide a concise and accurate summary for the new conversation above:\n",
      "\n",
      "The customer is complaining that he is not able to find the Red Eye Removal tool in Lightroom CC. The agent answered that the feature is not available in Lightroom CC as of now.\n",
      "\n",
      "---\n",
      "\n",
      "### Example Conversation:\n",
      "user: I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about the new Lightroom CC. I have a question about\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select a random conversation-summary pair from the train dataset for the one-shot example\n",
    "example_conversation_train = dataset['train'][0]['conversation']\n",
    "example_summary_train =  dataset['train'][0]['summary']\n",
    "\n",
    "# Select the conversation and the human-generated summary from the test dataset\n",
    "index = 100  \n",
    "dialogue_test = dataset['test'][index]['conversation']\n",
    "baseline_human_summary = dataset['test'][index]['summary']\n",
    "\n",
    "\n",
    "# Prepare the one-shot prompt\n",
    "prompt = f\"\"\"\n",
    "### Example Conversation:\n",
    "{example_conversation_train}\n",
    "\n",
    "### Example Summary:\n",
    "{example_summary_train}\n",
    "\n",
    "---\n",
    "\n",
    "### New Conversation:\n",
    "{dialogue_test}\n",
    "\n",
    "### Please provide a concise and accurate summary for the new conversation above:\n",
    "\"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs = {key: value.to(\"cuda:1\") for key, value in input_ids.items()} \n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    max_length=1024, \n",
    "    num_beams=1,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Generate the summary for the new conversation\n",
    "peft_model_outputs = peft_model.generate(input_ids=inputs[\"input_ids\"], generation_config=generation_config)\n",
    "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Output the results\n",
    "dash_line = '-' * 100\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{baseline_human_summary}')\n",
    "print(dash_line)\n",
    "print(f'ONE-SHOT MODEL OUTPUT:\\n{peft_model_text_output}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "whisper_asr",
   "language": "python",
   "name": "whisper_asr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01086900e35842a3982a72dd4dfd7ed4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "017d11b29e1b49f6915668c844d90be6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d824b707a5441b194a0ffa2406fe84e",
      "placeholder": "​",
      "style": "IPY_MODEL_e0020b5d0413433eac71332c8cb1d8e3",
      "value": "Your token has been saved in your configured git credential helpers (store)."
     }
    },
    "0311af00a4f3464caaddda4f3acdc075": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03e9c632eb31417282be6050a10a7ffe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "068bc0b8d9074b1487576a9f6d0682b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc6b0cbe3288481bac2e87112569aef0",
      "placeholder": "​",
      "style": "IPY_MODEL_2b036691b30a44be9d727ff033dbd76c",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "07206333d31a44959be04a5f8c586536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0747759e94ad43a8a15618c1815c696c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b134f1cff20483d927def2c0e94613c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1dcd269a5e0c4122a4fca7be44b0a35d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27a0b1787c144f04b3965cfbb41630fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b036691b30a44be9d727ff033dbd76c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b8f2bdf3611471e8e69b76a91eccbc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eafb01ed20e5473bab38e66d7697294b",
      "placeholder": "​",
      "style": "IPY_MODEL_7106e0589e394cacb1b0ac2051611c82",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "2cff06b3f37e429d8d09c1e5083fb292": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31017356c0fd47ccb6243673fe1f050e",
      "max": 18289,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a9e615fc3c3d47ef8ccedab33feec04e",
      "value": 18289
     }
    },
    "2d434c021c9d4395ad83a8ac8487bbf5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d824b707a5441b194a0ffa2406fe84e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31017356c0fd47ccb6243673fe1f050e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31ba866e30294a1d8586c887f4c6b1ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3355ec62d8a0490da97e02a4e94fc57a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bc37d8e72b647c783852e0ade88d54b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f62a453f03704800b99927ef4e455d8a",
      "placeholder": "​",
      "style": "IPY_MODEL_89ab0574cd9a4bfeaf8acd35b82fcff7",
      "value": "Login successful"
     }
    },
    "4408ec6e1f854c7688db481ead19d637": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69593d00ba1548369e6cce2d9c6500d8",
      "max": 111,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07206333d31a44959be04a5f8c586536",
      "value": 111
     }
    },
    "4715fb7fbffb461f936aa27ec00412dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48d064da1da04cffbd32b8440bdfdf04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "55e2b7232d974a7d926c1bcfea982297": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56a1b51b999e45c1942a200de8afaea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b61131c94e8f471db054027fe6fce205",
      "placeholder": "​",
      "style": "IPY_MODEL_01086900e35842a3982a72dd4dfd7ed4",
      "value": " 111/111 [00:00&lt;00:00, 3.96kB/s]"
     }
    },
    "5a92ebe052934dac967a008c6fa1b302": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c090d00c2f94676b19f6f5a9e43a146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "645c2980da484817ade24c762ddff101": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69593d00ba1548369e6cce2d9c6500d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "707a7305ea90444ca4f5b2b6cc4ca6a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f62d339badc74726b639c41293d6b318",
      "placeholder": "​",
      "style": "IPY_MODEL_0747759e94ad43a8a15618c1815c696c",
      "value": " 6.73k/6.73k [00:00&lt;00:00, 102kB/s]"
     }
    },
    "70caeec39c844f41bb9c3649c05410ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d434c021c9d4395ad83a8ac8487bbf5",
      "placeholder": "​",
      "style": "IPY_MODEL_5c090d00c2f94676b19f6f5a9e43a146",
      "value": "Token is valid (permission: write)."
     }
    },
    "7106e0589e394cacb1b0ac2051611c82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73dc9b7f901148949900ab6629f640f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73f0d6d8ab0042bc90436030127c3180": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ffd34f646342432a956810303aef59cf",
       "IPY_MODEL_da53bda3f01d46898b3a2105d7356c80",
       "IPY_MODEL_f6f0ca60a6ce4aa29f3c241b17e8fb46"
      ],
      "layout": "IPY_MODEL_88af9bfbc9f249088c3bbdc55be523a1"
     }
    },
    "7a7f8b5cb6a14d3b98110640b48f91cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f5a7e719af84485984fc4808f8b6266": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a92ebe052934dac967a008c6fa1b302",
      "placeholder": "​",
      "style": "IPY_MODEL_b9afeb9507744262bb59b3b6115e11d7",
      "value": "Downloading builder script: 100%"
     }
    },
    "83382c2e725f420b8fd162b7b8dd21d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8826761dbaf54bfa9e6a9d0f7fe7f999": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83382c2e725f420b8fd162b7b8dd21d2",
      "placeholder": "​",
      "style": "IPY_MODEL_4715fb7fbffb461f936aa27ec00412dc",
      "value": " 18.3k/18.3k [00:00&lt;00:00, 463kB/s]"
     }
    },
    "88af9bfbc9f249088c3bbdc55be523a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89ab0574cd9a4bfeaf8acd35b82fcff7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c15ee9843064c24853c890eb5703b51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "992ee5a93d4843c893d85435bc438bd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ae6eed0fb184269bc1c283078a4ec93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9bd7ad1dce1d4a88b7e4d5cae9b3b4e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c832cf7055d434285ddf8dd90480e9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cefd5b024dcd429cb0e71005b2e3de37",
       "IPY_MODEL_ba469a168231482cb09b5b8b53acf269",
       "IPY_MODEL_707a7305ea90444ca4f5b2b6cc4ca6a3"
      ],
      "layout": "IPY_MODEL_9bd7ad1dce1d4a88b7e4d5cae9b3b4e1"
     }
    },
    "a9e615fc3c3d47ef8ccedab33feec04e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b24659bf456549cd9adeb89a56624771": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_73dc9b7f901148949900ab6629f640f7",
      "placeholder": "​",
      "style": "IPY_MODEL_1b134f1cff20483d927def2c0e94613c",
      "value": ""
     }
    },
    "b61131c94e8f471db054027fe6fce205": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b63a102c63864cd6a9a4f06b117c28e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "b78321f7550043fa9e520201b7cd483a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5de76fcdd08405da1918e0874eabfbd",
      "placeholder": "​",
      "style": "IPY_MODEL_645c2980da484817ade24c762ddff101",
      "value": "generation_config.json: 100%"
     }
    },
    "b91b5f88a5d24fcb9228868de7773604": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9afeb9507744262bb59b3b6115e11d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba469a168231482cb09b5b8b53acf269": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3355ec62d8a0490da97e02a4e94fc57a",
      "max": 6727,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f4fa6c4eceb84b72b01949281cf36ffe",
      "value": 6727
     }
    },
    "bb5ce5f2678b4b1e8605c29b78d8e3db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be60703fb74541fd9f91a68b38f8ce98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c92c28b4bd724043aa4780471d04b4e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_70caeec39c844f41bb9c3649c05410ed",
       "IPY_MODEL_017d11b29e1b49f6915668c844d90be6",
       "IPY_MODEL_e5028d7f6bb74c7e932eaef1ddb9ee51",
       "IPY_MODEL_3bc37d8e72b647c783852e0ade88d54b"
      ],
      "layout": "IPY_MODEL_efe9e27b86b540d6b77385bce2b62d4f"
     }
    },
    "cb4e1af2b227433589feab9798332525": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ced0c2fd7ad14e16adb289d083a5ae9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27a0b1787c144f04b3965cfbb41630fb",
      "placeholder": "​",
      "style": "IPY_MODEL_bb5ce5f2678b4b1e8605c29b78d8e3db",
      "value": "Connecting..."
     }
    },
    "cefd5b024dcd429cb0e71005b2e3de37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c15ee9843064c24853c890eb5703b51",
      "placeholder": "​",
      "style": "IPY_MODEL_7a7f8b5cb6a14d3b98110640b48f91cb",
      "value": "Downloading readme: 100%"
     }
    },
    "d5c88931586841ea9204e8d3c2193de1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b78321f7550043fa9e520201b7cd483a",
       "IPY_MODEL_4408ec6e1f854c7688db481ead19d637",
       "IPY_MODEL_56a1b51b999e45c1942a200de8afaea8"
      ],
      "layout": "IPY_MODEL_cb4e1af2b227433589feab9798332525"
     }
    },
    "d5de76fcdd08405da1918e0874eabfbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da53bda3f01d46898b3a2105d7356c80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f38eaf716a424225979b7eec4b7e2a05",
      "max": 5590927496,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_48d064da1da04cffbd32b8440bdfdf04",
      "value": 5590927496
     }
    },
    "dc6b0cbe3288481bac2e87112569aef0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0020b5d0413433eac71332c8cb1d8e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e13406f92c824ee3b292de898148dc04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f5a7e719af84485984fc4808f8b6266",
       "IPY_MODEL_2cff06b3f37e429d8d09c1e5083fb292",
       "IPY_MODEL_8826761dbaf54bfa9e6a9d0f7fe7f999"
      ],
      "layout": "IPY_MODEL_992ee5a93d4843c893d85435bc438bd0"
     }
    },
    "e4f4f4e0f073479cb44a288b195db2bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5028d7f6bb74c7e932eaef1ddb9ee51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0311af00a4f3464caaddda4f3acdc075",
      "placeholder": "​",
      "style": "IPY_MODEL_31ba866e30294a1d8586c887f4c6b1ad",
      "value": "Your token has been saved to /root/.cache/huggingface/token"
     }
    },
    "e5dd3b54a1b2466fa62ebbbe1176153e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_55e2b7232d974a7d926c1bcfea982297",
      "style": "IPY_MODEL_b63a102c63864cd6a9a4f06b117c28e9",
      "tooltip": ""
     }
    },
    "e8f80ec8c697433aa7d2e7b6cd4e62fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_be60703fb74541fd9f91a68b38f8ce98",
      "style": "IPY_MODEL_e4f4f4e0f073479cb44a288b195db2bb",
      "value": true
     }
    },
    "eafb01ed20e5473bab38e66d7697294b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efe9e27b86b540d6b77385bce2b62d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "f38eaf716a424225979b7eec4b7e2a05": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4fa6c4eceb84b72b01949281cf36ffe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f62a453f03704800b99927ef4e455d8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f62d339badc74726b639c41293d6b318": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6f0ca60a6ce4aa29f3c241b17e8fb46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dcd269a5e0c4122a4fca7be44b0a35d",
      "placeholder": "​",
      "style": "IPY_MODEL_9ae6eed0fb184269bc1c283078a4ec93",
      "value": " 5.59G/5.59G [01:42&lt;00:00, 57.1MB/s]"
     }
    },
    "ffd34f646342432a956810303aef59cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03e9c632eb31417282be6050a10a7ffe",
      "placeholder": "​",
      "style": "IPY_MODEL_b91b5f88a5d24fcb9228868de7773604",
      "value": "model.safetensors: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
